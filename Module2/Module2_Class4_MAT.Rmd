---
title: "Class 2-4: Wrapping up Module 2"
author: "Health Data Analysis Practicum (AS.280.347)"
date: "March 23, 2020"
output: 
  html_document:
    toc: true
    toc_float: 
      toc_collapsed: true
    toc_depth: 3
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = TRUE)
knitr::opts_knit$set(root.dir = "/cloud/project")
```

## Module 2: Factors that are associated with development of hypertension

Recall that our main questions of interest are:

  * Question 2.1: What factors measured in the NYC HANES survey are associated with having hypertension?
  * Question 2.2: How do our estimates from survey-weighted logistic regression differ from those where we ignore survey weights?


The learning objectives for this module include:

  * data cleaning/visualization
  * logistic regression
  * survey-weighted analysis
  * selection of survey weights for unbalanced data

## Reminder: What are the data?

For this case study, we will use data from the [New York City (NYC) Health and Nutrition Examination Survey (NYC HANES)](http://nychanes.org/){target="_blank"}, 
modeled on the 
[National Health and Nutrition Examination Survey (NHANES)](https://wwwn.cdc.gov/nchs/nhanes/default.aspx){target="_blank"}. NHANES is a population-based, cross-sectional study with data collected 
from a physical examination and laboratory tests, as well as a face-to-face 
interview and an audio computer-assisted self-interview (ACASI). It is 
designed to assess the health and nutritional status of adults and children 
in the United States. NYC HANES is a local version of NHANES, which implies 
it mainly focuses on New York area. 


## Learning objectives for today

Our main question of interest for this module is: Based on the data collected from NYC HANES, which risk factors play a role in development of hypertension?

Today, we will continue to work toward answering this by learning how to:

* Further discuss strategies for approaching model selection: how do you decide what variables to include in your model and how do you compare different models?
* Touch base on any questions about selecting the correct survey weights to use in your analysis.
* Understand how to include inline R code and why it is useful.
* Describe what makes an effective comparison of survey-weighted and unweighted model results.
* Touch base about your final projects to hear what you have been working on so far.


### Selecting the weights

Because the NYC HANES 2013-2014 data have been collected to 
address a variety of different questions and using different 
surveys, the researchers who produced the data have employed a 
somewhat complex weighting scheme to compensate for unequal 
probability of selection. Five sets of survey weights have been 
constructed to correspond to different sets of variables that were
collected: CAPI  weight, Physical weight, Blood Lab result weight,
Urine Lab results weight and Salica Lab results weight. 
**The determination of the most appropriate weight to use for a specific analysis depends upon the variables selected by the data analyst**. 


We will give a table to indicate each variable's origin stream:


| Variable names   |      Component      |
|---------------------------------|---------------------------------|
| age                                   | CAPI                                                                                                                                                                 |
| race                                  | CAPI                                                                                                                                                                 |
| gender                                | CAPI                                                                                                                                                                 |
| diet                                  | CAPI                                                                                                                                                                 |
| income                                | CAPI                                                                                                                                                                 |
| diabetes                               | CAPI                                                                                                                                                               |
| cholesterol                           | CAPI                                                                                                                                                                 |
| drink                                 | CAPI                                                                                                                                                                 |
| smoking                               | CAPI                                                                                                                                                                 |
| hypertension                           | CAPI                                                                                                                                                                |
| bmi                                    | EXAM                                                                                                                                                                |


When an analysis involves variables from different components
of the survey, the analyst should decide whether the outcome 
is inclusive or exclusive, and then choose certain weights. 
To learn how to use weights for different purposes, refer to the particular
[Analytics Guidelines](http://nychanes.org/wp-content/uploads/sites/6/2015/11/ANALYTIC-GUIDELINES-2016_V2.pdf) for the survey. 

In our case, we choose EXAM weight since our analysis is exclusive. Do 
you remember we have removed all of the missing values? Now our dataset is 
limited to those who received a physical exam test, which means all of our 
survey participants have a value for the `EXAM_WT` variable. We selected
this variable and renamed it as `surveyweight` in the earlier data 
cleaning part of this analysis. 

NYC HANES has put together some really useful documentation to give some further examples of how to select the correct weight to use in different cases: the slideshow at [Weight Adjustment](http://nychanes.org/wp-content/uploads/sites/6/2015/11/NYC-HANES-Training-Slides_part-2_08222016.pdf){target="_blank"} explains how the NYC HANES data are weighted in order to compensate for unequal probability of selection and explains how to choose the correct weight for analysis, including some hypothetical analysis scenarios. In order to determine the sources of the different variables, you can refer to the [Variable Codebook](http://nychanes.org/wp-content/uploads/sites/6/2019/01/28283961_NYC-HANES_codebook_Public_V3_011019.pdf){target="_blank"}.




## Your work for this week: questions raised over email

### What is inline R code and why is it useful?

Start by loading libraries and raw data set.
```{r}
library(tidyverse)  # core group of tidyverse packages
library(knitr)  # to make nice tables
library(ggpubr)
library(ggrepel)
library(tidyverse)
library(kableExtra)
library(survey)
library(haven)
library(broom)
library(plotrix)
library(pander)

dat <- read_sas('Module2/data/d.sas7bdat')
dim(dat)
```

```{r , echo=FALSE}
### put recoding data here

### renaming the 13 variables considered in our analysis

hy_df <- 
  dat %>% 
    select(id = KEY,
           age = SPAGE,
           race = DMQ_14_1,
           gender = GENDER,
           diet = DBQ_1,
           income = INC20K,
           diabetes = DIQ_1,
           bmi = BMI,
           cholesterol = BPQ_16,
           drink = ALQ_1_UNIT,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2,
           surveyweight = EXAM_WT)

### merging answers to ALQ_1 to ALQ_1_unit as one to better capture drinking that includes those who never drink. We label those subjects who answered 0 to variable AlQ_1 (those who never drink) as 4.

hy_df <- hy_df %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))

### (1) converting categorical variables to factors using the nummerical values and categoy labels given in the Variable Codebook. (2) creating a natural ordering to the factor levels.

hy_df <- hy_df %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('Less than $20,000','$20,000 - $39,999',
                                 '$40,000 - $59,999','$60,000 - $79,999',
                                 '$80,000 - $99,999','$100,000 or more')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,1,2,3), 
                       labels=c('Never','Weekly', 'Monthly', 'Yearly')),
                     smoking = factor(smoking, levels=c(3:1), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes'))
                     )

hy_p_df <- 
  hy_df %>%
  drop_na()

```

```{r}
### specify the design relative to our dataset
hypertension_design <- svydesign(
  id = ~1,
  weights = ~hy_p_df$surveyweight,
  data = hy_p_df
  )

### survey-weighted logistic regression -- not including bmi
g1 <- svyglm(hypertension ~ 
               age + cholesterol + income + 
               diabetes,
              family = quasibinomial(link = 'logit'), 
             design = hypertension_design)

pander(g1, 
       add.significance.stars=T)

g1_res <- tidy(g1)
g1_res_exp<-exp(g1$coefficients)

g1_res
g1_res_exp
```

Suppose I wanted to write some sentences to summarize what this model output is telling us. I could run the code, look at the numbers, and then type them here:

For example:
Holding all other variables constant, a one-unit increase in age is associated with a 3.9% increase in the odds of hypertension. This is statistically significantly different from zero because it has a p value of 5.596290e-13, which is < 0.05.

Instead of running the code and copying the numbers from the output, you could pull them directly from the R objects using code:
Holding all other variables constant, a one-unit increase in age is associated with  `r round(100*g1_res_exp["age"] - 100,1)`% increase in the odds of hypertension. This is statistically significantly different from zero because it has a p value of `r format(g1_res %>% filter(term=="age") %>% pull(p.value), digits=3)`, which is < 0.05.

Although you can't see it in the knitted document, this second paragraph does not contain the numbers themselves, but R code to generate and format the numbers that should be included in the model write-up. For example, to generate the percent increase, the code is: `round(100*g1_res_exp["age"] - 100,1)`. And to generate the p-value, it is `format(g1_res %>% filter(term=="age") %>% pull(p.value), digits=3)`.


Why is this useful? 
* It is not susceptible to typos, i.e., copying and pasting the wrong numbers.
* It is easy to update, for example, if you fit a new model. Suppose you realize that you actually meant to include BMI as a covariate. 

```{r}
### survey-weighted logistic regression -- not including bmi
g1 <- svyglm(hypertension ~ 
               bmi + age + cholesterol + income + 
               diabetes,
              family = quasibinomial(link = 'logit'), 
             design = hypertension_design)

pander(g1, 
       add.significance.stars=T)

g1_res <- tidy(g1)
g1_res_exp<-exp(g1$coefficients)

confint(g1)

#g1_res <- cbind(g1_res, confint(g1))

#g1_res <- g1_res %>% mutate(OR = exp(estimate))
#g1_res <- g1_res %>% mutate(OR_CI_low = exp(`2.5 %`), OR_CI_high = exp(`97.5 %`))

```

If I had hard-coded numbers into my output summary, I would have to go back and re-write and double check the numbers. But if I have used code, the same code will just give me updated results:

Holding all other variables constant, a one-unit increase in age is associated with  `r round(100*g1_res_exp["age"] - 100,1)`% increase in the odds of hypertension. This is statistically significantly different from zero because it has a p value of `r format(g1_res %>% filter(term=="age") %>% pull(p.value), digits=3)`, which is < 0.05.

A few tips to make things easier:
* You will probably want to save your model output and/or some processed versions in R objects that you can easily refer to in your inline code, like `g1_res` and `g1_res_exp` above.
* You should try to use variable names and the tidyverse piping commands as much as possible, rather than indexing into specific rows or columns of your output. For example, if you had written code referring to `age` as the first variable in the model (for example using `g1_res_exp[2]` to access the odds ratio), this would be incorrect in the new model, where `bmi` is included before `age`.

```{r}
foo <- "this is a test"
```

Print `r foo`.


### Some points of discussion

What are some model selection techniques that you all have been trying?

Has anyone seen anything new and surprising this week in terms of model results?



## Getting to Question 2.2

Recall Question 2.2: How do our estimates from survey-weighted logistic regression differ from those where we ignore survey weights?

To answer this, use your final model from your survey-weighted analysis and fit a standard (unweighted) logistic regression instead. How might you want to compare the results of these two models? A table? Some kind of visualization?

<center>
![](data/FinalPlot.png)
</center>

How would we go about making a figure like this? We first need to create a data frame with odds ratios and confidence intervals for the two methods. Recall that we created a nice data frame of the output of our survey-weighted glm using the `tidy` function:

```{r}
g1_res
```

We want to use this model output to create a data frame with the values we want to plot.

```{r }
g1_res <- cbind(g1_res, confint(g1))
g1_res
```

We then want to fit the same model using un-weighted logistic regression: 

```{r}
### unweighted logistic regression
g1_noWt <- glm(hypertension ~ 
               bmi + age + cholesterol + income + 
               diabetes,
              family = quasibinomial(link = 'logit'), data=hy_p_df)

pander(g1_noWt, 
       add.significance.stars=T)

g1_noWt_res <- tidy(g1_noWt)
g1_noWt_res

g1_noWt_res <- cbind(g1_noWt_res, confint(g1_noWt))
g1_noWt_res
```

To plot these results on the same plot, we need to combine these two results into one data frame, with some indicator of which results are which.

```{r}

g1_res <- g1_res %>% mutate(method="Weighted")
g1_noWt_res <- g1_noWt_res %>% mutate(method="Unweighted")

g1_both<-rbind(g1_res, g1_noWt_res)

```

We can try a couple different ways of combining these results:

```{r}
g1_both %>% ggplot(aes(x=estimate, y=term))+
    xlab("Difference in log odds (95% Confidence Interval)")+
    geom_errorbarh(aes(xmin=`2.5 %`, xmax=`97.5 %`,col=method),width=0.5,cex=1)+ 
    facet_wrap(~term,strip.position="left",nrow=9) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_point(aes(color = factor(method),
                    shape = factor(method)),size = 3)+
    theme(plot.title=element_text(size=16,face="bold"),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))
 

g1_both %>% ggplot(aes(x=estimate, y=term))+
    xlab("Difference in log odds (95% Confidence Interval)")+
    geom_errorbarh(aes(xmin=`2.5 %`, xmax=`97.5 %`,col=method),width=0.5,cex=1)+ 
    facet_wrap(~term,strip.position="left",nrow=9, scales="free_x") +
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_point(aes(color = factor(method),
                    shape = factor(method)),size = 3)+
    theme(plot.title=element_text(size=16,face="bold"),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))


 g1_both %>% ggplot(aes(x = estimate, y = term),
     group_by(g1_both$method)) +
     geom_vline(xintercept = 0, linetype = "dashed") +
     geom_errorbarh(aes(estimate, term, xmin = `2.5 %`, 
     xmax = `97.5 %`, color = factor(method),width = 0.3), size = 0.8)+
     geom_point(aes(color = factor(method),
                    shape = factor(method)),size = 3)+
    theme(axis.title.x = element_blank(),
    axis.title.y = element_blank()) +
    ggtitle(expression(atop(bold("95% condfidence interval"))))+
   theme_minimal()

 
g1_both %>% filter(term != "(Intercept)") %>% ggplot(aes(x = estimate, y = term),
     group_by(g1_both$method)) +
     geom_vline(xintercept = 0, linetype = "dashed") +
     geom_errorbarh(aes(estimate, term, xmin = `2.5 %`, 
     xmax = `97.5 %`, color = factor(method),width = 0.3), size = 0.8)+
     geom_point(aes(color = factor(method),
                    shape = factor(method)),size = 3)+
    theme(axis.title.x = element_blank(),
    axis.title.y = element_blank()) +
    ggtitle(expression(atop(bold("95% condfidence interval"))))+
   theme_minimal()

```

Note that these are not finalized -- they are just some suggestions to help get you started!

### Model selection

You've now fit at least one model using these data. But how do you know if it is a good model for answering our question of interest? There are many approaches to answering this question.

One way you can decide what variables to include in a model is by looking at whether the model coefficients associated with those variables are statistically significantly different from zero. This tells you whether the value of the outcome (in this case log odds of having hypertension) varies as this particular input variable changes, considering all other variables in your model. So you can look at the t-statistics and p-values associated with this variable to see whether you would reject the null hypothesis that the parameters associated with this variable are zero. 


```{r read-data, echo=FALSE}
hy_df <- 
  dat %>% 
    select(id = KEY,
           age = SPAGE,
           race = DMQ_14_1,
           gender = GENDER,
           diet = DBQ_1,
           income = INC20K,
           diabetes = DIQ_1,
           bmi = BMI,
           cholesterol = BPQ_16,
           drink = ALQ_1_UNIT,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2,
           surveyweight = EXAM_WT)

hy_df <- hy_df %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))

hy_df <- hy_df %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('Less than $20,000','$20,000 - $39,999',
                                 '$40,000 - $59,999','$60,000 - $79,999',
                                 '$80,000 - $99,999','$100,000 or more')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,1,2,3), 
                       labels=c('Never','Weekly', 'Monthly', 'Yearly')),
                     smoking = factor(smoking, levels=c(3:1), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes'))
                     )

## remove entries with missing data
hy_p_df <- 
  hy_df %>%
  drop_na()

hypertension_design <- svydesign(
  id = ~1,
  #fpc = ~rep(N,n),
   weights = ~hy_p_df$surveyweight,
  data = hy_p_df
)
```


For example, we can look at these two models that we fit last week:

```{r, warning=TRUE}
g0 <- svyglm(hypertension ~ smoking, 
    family = quasibinomial(link = 'logit'), design = hypertension_design)
summary(g0)

g1 <- svyglm(hypertension ~ 
               age + race + gender + diet + income + 
               diabetes + bmi + cholesterol + drink + smoking,
             family = quasibinomial(link = 'logit'), 
             design = hypertension_design)
summary(g1)
```


Not all of the variables in our full model `g1` are considered statistically significant so we would perhaps
like to remove some of them to get a reduced model. However, you may want to keep a variable in the model, even if the coefficients are not significantly different from zero if that variable is important for the question you are trying to answer.

It's also often nice to get a value that summarizes how well your model fits the data. To do this here, we'll use an approach referred to as Akaike's "An Information Criterion," or `AIC()`. We won't disucss detail here, but the lower an AIC for a model, the better that model fits the data.

Below, we can see that `g1`, where we include multiple predictors has the lowest AIC value. Looking at this value combined with your model summary output will help you determine which of your models is the best choice for your final analysis.

```{r}
AIC(g0, g1)
```

#### Some further notes on survey weights

Remember that the weight variable that you use will depend on the set of variables that will be included in your final model. You may need to revisit this choice depending on what your final model is.

## Assignment 2.4 (final project for Module 2)

Write a complete report investigating the questions of interest from this module. Your report should include:

* Some simple/concise background on the data set and a clear presentation of the question you want to answer;
* An exploratory data analysis, where you use data visualizations (tables and figures) to illustrate relationships between variables in the data set, as they relate to the question you are interested in answering, and then discuss what these visualizations tell you;
* Model results presented in a tidy way, perhaps with a nice table of relevant coefficients and p-values, including a clear discussion of the effects of the variables included in the model;
* A comparison of results from the survey-weighted model to those from a standard glm, and a brief discussion of what you see.


In the written portions of your report, think about connecting each table or visualization that you make with your downstream modeling choices. How do your displays point you toward the model you end up fitting? 

Also, think about justifying each choice of variable in your model: can you use a visualization to do this? Look at significance of coefficients? Talk about how you are curious about a specific variable and how it influences hypertension? Compare models using AIC to decide on your final model?

What is an effective way of illustrating how the results of the weighted and unweighted approaches compare?

Finally, try to make your report as readable as possible: hide any R code or warning messages, try to make the tables readable, etc. 

* Submit your updated analysis report in R Markdown through Github by Sunday March 29, 2020 at midnight.
* You may work together on this assignment, but you must submit your own report; please credit in your assignment anyone with whom you collaborated.
* Next week in class we will continue with discussion of your final project ideas.

## Looking ahead to your final projects

<center>
![](../Module3/Project1.png)
</center>

<center>
![](../Module3/Project2.png)
</center>

